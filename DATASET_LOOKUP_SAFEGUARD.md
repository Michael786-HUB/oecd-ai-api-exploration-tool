# Dataset Lookup Safeguard

## Problem

**User Query**: "From the `DSD_NASEC10@DF_TABLE11` dataset, I want US government spending on military in 2024"

**AI Response** (before fix):
```
I understand you're looking for US government military spending data for 2024, but I need to let
you know that the specific dataset ID you mentioned (DSD_NASEC10@DF_TABLE11) doesn't appear in
the OECD catalog I have access to.
```

**Reality**: The dataset DOES exist in the catalog!

**Root Cause**:
- AI only sees first 25 datasets per category in its context
- `DSD_NASEC10@DF_TABLE11` is the 38th dataset in "Public governance" category
- Not in AI's limited view ‚Üí AI thinks it doesn't exist
- User gets frustrated and confused

---

## Solution: Pre-Query Dataset Lookup

### How It Works

```
User Query ‚Üí Extract Dataset IDs ‚Üí Validate Against Catalog ‚Üí Inject Details into AI Prompt
     ‚Üì                                        ‚Üì
  "Show me                              ‚úÖ Valid?
   DSD_XXX data"                            ‚Üì
                                    Add to AI context
                                            ‚Üì
                                    AI: "Here's DSD_XXX!"
```

### Step 1: Extract Dataset IDs from User Query

**Location**: [app.py:234-246](app.py#L234-L246)

```python
def extract_dataset_ids_from_query(query_text):
    """
    Extract potential dataset IDs from user query (without backticks).
    More lenient pattern to catch dataset mentions in natural language.
    """
    import re

    # Pattern matches dataset IDs even without backticks
    # Matches: DSD_XXX@DF_YYY or similar patterns
    pattern = r'\b([A-Z][A-Z0-9_]*(?:@[A-Z][A-Z0-9_]*)?)\b'
    matches = re.findall(pattern, query_text)

    # Filter to keep only valid-looking dataset IDs
    dataset_ids = [m for m in matches if "@" in m or m.startswith("DSD_") or m.startswith("DF_") or m.startswith("SEEA_")]

    return dataset_ids
```

**Examples**:
- Input: `"Show me DSD_NASEC10@DF_TABLE11 data"`
  - Output: `['DSD_NASEC10@DF_TABLE11']`

- Input: `"I want data from DSD_GDP@DF_QNA for USA"`
  - Output: `['DSD_GDP@DF_QNA']`

- Input: `"Compare DSD_LFS@DF_IALFS and DSD_UNEMPLOYMENT@DF_DATA"`
  - Output: `['DSD_LFS@DF_IALFS', 'DSD_UNEMPLOYMENT@DF_DATA']`

---

### Step 2: Validate Dataset IDs

**Location**: [app.py:248-268](app.py#L248-L268)

```python
def validate_dataset_ids(dataset_ids, catalog):
    """Validate that dataset IDs exist in the catalog."""
    valid_ids = []
    invalid_ids = []

    for dataset_id in dataset_ids:
        found = False
        for category, cat_data in catalog.items():
            if dataset_id in cat_data["datasets"]:
                valid_ids.append(dataset_id)
                found = True
                break
        if not found:
            invalid_ids.append(dataset_id)

    return valid_ids, invalid_ids
```

---

### Step 3: Lookup Dataset Details

**Location**: [app.py:270-296](app.py#L270-L296)

```python
def lookup_dataset_details(dataset_ids, catalog):
    """
    Look up detailed information for specific dataset IDs.
    Returns formatted string with dataset details for AI context.
    """
    details = []

    for dataset_id in dataset_ids:
        for category, cat_data in catalog.items():
            if dataset_id in cat_data["datasets"]:
                metadata = cat_data["datasets"][dataset_id]
                name = metadata.get('name', 'Unknown')
                desc = metadata.get('description', 'No description available')[:200]
                agency = metadata.get('agency', 'Unknown')

                detail_text = f"""
**USER-MENTIONED DATASET (PRIORITIZE THIS):**
- ID: `{dataset_id}`
- Name: {name}
- Category: {category}
- Agency: {agency}
- Description: {desc}...

This dataset was explicitly mentioned by the user. Make this your TOP RECOMMENDATION.
"""
                details.append(detail_text)
                break

    return "\n".join(details) if details else ""
```

**Output Example**:
```
**USER-MENTIONED DATASET (PRIORITIZE THIS):**
- ID: `DSD_NASEC10@DF_TABLE11`
- Name: Annual government expenditure by function (COFOG)
- Category: Public governance
- Agency: OECD.SDD.NAD
- Description: This table provides a breakdown of government expenditure according to
  the Classification of the Functions of Government (COFOG), which shows how much
  governments spend in areas such as health, education, defense...

This dataset was explicitly mentioned by the user. Make this your TOP RECOMMENDATION.
```

---

### Step 4A: Immediate Feedback for Invalid IDs

**Location**: [app.py:735-750](app.py#L735-L750)

If user mentions invalid dataset IDs, show error **immediately** (before calling AI):

```python
# Validate mentioned IDs
if mentioned_ids:
    valid_mentioned, invalid_mentioned = validate_dataset_ids(mentioned_ids, catalog)

    # If user mentioned invalid dataset IDs, show error immediately
    if invalid_mentioned:
        with st.chat_message("assistant"):
            st.error(f"‚ö†Ô∏è Dataset not found: {', '.join(invalid_mentioned)}")
            st.markdown(f"The dataset ID(s) you mentioned don't exist in the OECD catalog.
                        Please check the ID and try again, or describe what data you're
                        looking for and I'll help you find the right dataset.")

        # Don't call AI - user needs to fix the ID first
        st.rerun()
```

---

### Step 4B: Inject Details for Valid IDs

**Location**: [app.py:115-122](app.py#L115-L122)

If user mentions valid dataset IDs, add their details to AI prompt:

```python
catalog_summary = build_catalog_summary(catalog)

# Check if user mentioned specific dataset IDs
mentioned_ids = extract_dataset_ids_from_query(user_question)
if mentioned_ids:
    valid_mentioned, _ = validate_dataset_ids(mentioned_ids, catalog)
    if valid_mentioned:
        # Add detailed info about mentioned datasets to the prompt
        dataset_details = lookup_dataset_details(valid_mentioned, catalog)
        catalog_summary = dataset_details + "\n\n" + catalog_summary  # PREPEND!
```

**Key**: Dataset details are **prepended** (added at top) so AI sees them first!

---

## User Experience Examples

### Example 1: Valid Dataset Mentioned

**User**: "From the `DSD_NASEC10@DF_TABLE11` dataset, I want US government spending on military in 2024"

**System Flow**:
1. ‚úÖ Extract: `DSD_NASEC10@DF_TABLE11`
2. ‚úÖ Validate: Found in catalog
3. ‚úÖ Lookup details: Get name, description, etc.
4. ‚úÖ Inject into AI prompt at TOP
5. ‚úÖ AI sees: "USER-MENTIONED DATASET (PRIORITIZE THIS)..."

**AI Response** (after fix):
```
Perfect! I can help you with that. The dataset you mentioned is:

**Annual government expenditure by function (COFOG)** (`DSD_NASEC10@DF_TABLE11`)
- Category: Public governance
- What it offers: This dataset provides a breakdown of government expenditure according
  to COFOG classification, including defense/military spending
- Why it's relevant: This is exactly what you need for US military spending data

To get US military spending for 2024:
1. Select this dataset
2. Choose dimension filters:
   - Country: United States
   - Function: Defense (COFOG code: 02)
   - Time period: 2024

Would you like me to help you download this data?
```

---

### Example 2: Invalid Dataset Mentioned

**User**: "Show me data from `FAKE_DATASET@DF_NOTREAL`"

**System Flow**:
1. ‚úÖ Extract: `FAKE_DATASET@DF_NOTREAL`
2. ‚ùå Validate: Not found in catalog
3. ‚ö†Ô∏è Show error immediately (DON'T call AI)

**App Response**:
```
‚ö†Ô∏è Dataset not found: FAKE_DATASET@DF_NOTREAL

The dataset ID(s) you mentioned don't exist in the OECD catalog. Please check the ID
and try again, or describe what data you're looking for and I'll help you find the
right dataset.
```

**Benefits**:
- Instant feedback (no wasted AI call)
- Clear error message
- Helpful suggestion (describe what you want instead)

---

### Example 3: Multiple Datasets Mentioned

**User**: "Compare `DSD_LFS@DF_IALFS_UNE_M` and `DSD_NAAG@DF_NAAG` for Canada"

**System Flow**:
1. ‚úÖ Extract: `['DSD_LFS@DF_IALFS_UNE_M', 'DSD_NAAG@DF_NAAG']`
2. ‚úÖ Validate: Both found
3. ‚úÖ Lookup details for both
4. ‚úÖ Inject both into AI prompt

**AI Response**:
```
Great question! You've selected two excellent datasets for comparison:

1. **Labour Force Statistics - Unemployment** (`DSD_LFS@DF_IALFS_UNE_M`)
   - Category: Labour
   - Monthly unemployment rates and demographics

2. **Quarterly National Accounts** (`DSD_NAAG@DF_NAAG`)
   - Category: National Accounts
   - GDP, government spending, economic indicators

For Canada, you can:
- Track unemployment trends over time (LFS)
- Compare with economic growth (NAAG)
- Identify correlations between GDP and unemployment

Both datasets support country filtering for Canada. Would you like help setting up
the downloads?
```

---

## Technical Details

### Pattern Matching

**Regex Pattern**: `r'\b([A-Z][A-Z0-9_]*(?:@[A-Z][A-Z0-9_]*)?)\b'`

**Breakdown**:
- `\b` - Word boundary
- `[A-Z]` - Starts with uppercase letter
- `[A-Z0-9_]*` - Followed by uppercase, digits, or underscores
- `(?:@[A-Z][A-Z0-9_]*)?` - Optionally has `@` and more characters
- `\b` - Word boundary

**Matches**:
- ‚úÖ `DSD_NASEC10@DF_TABLE11`
- ‚úÖ `DSD_LFS`
- ‚úÖ `DF_IALFS_UNE_M`
- ‚úÖ `SEEA_WATER`

**Doesn't Match**:
- ‚ùå `lowercase_text`
- ‚ùå `Mixed_Case`
- ‚ùå `123_NUMBERS_FIRST`

---

### Validation Performance

**Complexity**: O(n √ó m) where:
- n = number of mentioned IDs
- m = number of categories

**Typical Performance**:
- 1 dataset ID, ~30 categories: <1ms
- 3 dataset IDs, ~30 categories: <3ms

**Optimization Opportunity**:
- Could pre-build a hash map: `{dataset_id: (category, metadata)}`
- Would reduce to O(n) lookups
- Not needed yet - current performance is fine

---

## Edge Cases Handled

### Case 1: Dataset ID in Middle of Sentence

**Query**: "I heard that DSD_NASEC10@DF_TABLE11 has good data"

**Result**: ‚úÖ Extracted and validated

---

### Case 2: Multiple IDs, Some Valid, Some Invalid

**Query**: "Compare VALID_ID@DF_DATA and FAKE_ID@DF_NOPE"

**Result**:
- ‚ö†Ô∏è Shows error for FAKE_ID
- Stops processing (user must fix)

---

### Case 3: ID Without @ Symbol

**Query**: "Show me DSD_NASEC10 data"

**Pattern Match**: ‚úÖ Matches (@ is optional)
**Validation**: ‚ùå Likely fails (most datasets have @)
**Result**: User gets "not found" message

---

### Case 4: Lowercase Dataset ID

**Query**: "Show me dsd_nasec10@df_table11"

**Pattern Match**: ‚ùå Doesn't match (requires uppercase)
**Result**: Not extracted, AI tries to help with general query

**Note**: OECD dataset IDs are uppercase. This is correct behavior.

---

### Case 5: Dataset ID in Backticks

**Query**: "Show me `DSD_NASEC10@DF_TABLE11` data"

**Pattern Match**: ‚úÖ Matches (backticks ignored by word boundaries)
**Result**: Works correctly

---

## Before vs After Comparison

### Before: AI Denies Existence

```
User: "From DSD_NASEC10@DF_TABLE11, I want US military spending"

AI: "I need to let you know that the specific dataset ID you mentioned
(DSD_NASEC10@DF_TABLE11) doesn't appear in the OECD catalog I have access to."

User: "But I saw it in the catalog!"  üò°
```

**Problem**: AI only sees 25 datasets per category, misses many datasets

---

### After: AI Confirms and Helps

```
User: "From DSD_NASEC10@DF_TABLE11, I want US military spending"

[System extracts "DSD_NASEC10@DF_TABLE11"]
[System validates: ‚úÖ Found]
[System injects details into AI prompt]

AI: "Perfect! The dataset you mentioned is Annual government expenditure
by function (COFOG). This dataset provides exactly what you need for US
military spending data. Here's how to get it..."

User: "Great!"  üòä
```

**Solution**: Pre-query lookup ensures AI always knows about mentioned datasets

---

## Testing

### Test 1: Valid Dataset Mention

```python
# Simulate user query
query = "From the DSD_NASEC10@DF_TABLE11 dataset, show me US data"

# Extract IDs
mentioned = extract_dataset_ids_from_query(query)
# ‚Üí ['DSD_NASEC10@DF_TABLE11']

# Validate
valid, invalid = validate_dataset_ids(mentioned, catalog)
# ‚Üí valid = ['DSD_NASEC10@DF_TABLE11'], invalid = []

# Lookup details
details = lookup_dataset_details(valid, catalog)
# ‚Üí Contains full dataset info
```

**Expected**: AI receives dataset details and recommends it ‚úÖ

---

### Test 2: Invalid Dataset Mention

```python
query = "Show me FAKE_DATASET@DF_TEST"

mentioned = extract_dataset_ids_from_query(query)
# ‚Üí ['FAKE_DATASET@DF_TEST']

valid, invalid = validate_dataset_ids(mentioned, catalog)
# ‚Üí valid = [], invalid = ['FAKE_DATASET@DF_TEST']
```

**Expected**: User sees error immediately, AI not called ‚úÖ

---

### Test 3: No Dataset Mentioned

```python
query = "Show me healthcare data for Canada"

mentioned = extract_dataset_ids_from_query(query)
# ‚Üí []
```

**Expected**: Normal AI flow, no special handling ‚úÖ

---

## Files Modified

**[app.py](app.py)**:
1. Added `extract_dataset_ids_from_query()` (lines 234-246)
2. Added `lookup_dataset_details()` (lines 270-296)
3. Updated `ask_ai_librarian()` to inject dataset details (lines 115-122)
4. Added pre-query validation in chat input (lines 735-750)

---

## Configuration

### Adjust Pattern Matching

To make pattern more/less strict:

```python
# Current (strict): Must be uppercase
pattern = r'\b([A-Z][A-Z0-9_]*(?:@[A-Z][A-Z0-9_]*)?)\b'

# More lenient (allow lowercase):
pattern = r'\b([A-Za-z][A-Za-z0-9_]*(?:@[A-Za-z][A-Za-z0-9_]*)?)\b'

# Even stricter (require @ symbol):
pattern = r'\b([A-Z][A-Z0-9_]*@[A-Z][A-Z0-9_]*)\b'
```

### Adjust Description Length

```python
# Current: 200 character description
desc = metadata.get('description', 'No description available')[:200]

# Longer (more context):
desc = metadata.get('description', 'No description available')[:500]

# Shorter (save tokens):
desc = metadata.get('description', 'No description available')[:100]
```

---

## Summary

The dataset lookup safeguard provides:

1. ‚úÖ **Pre-query extraction**: Finds dataset IDs in user query
2. ‚úÖ **Instant validation**: Checks if IDs exist in catalog
3. ‚úÖ **Immediate feedback**: Shows errors for invalid IDs
4. ‚úÖ **Context injection**: Adds valid dataset details to AI prompt
5. ‚úÖ **Prioritization**: AI told to make mentioned datasets TOP recommendations

**Result**: Users can mention specific dataset IDs and AI will always:
- Know if they exist or not
- Provide accurate information
- Recommend them as top priority

No more "dataset doesn't exist" errors for real datasets! üéâ
